{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习纳米学位"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 猫狗大战\n",
    "夏国栋  \n",
    "04-05, 2019"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 开题报告\n",
    "\n",
    "### 课题背景\n",
    "$~~~~~~~$猫狗大战 (Dogs vs. Cats Redux: Kernels Edition) 是 Kaggle 发起的一个娱乐性比赛项目，基于2013年发起的猫狗大战 (Dogs vs. Cats)，要求参赛者使用当前热门的工具和技术，例如： Jupyter Notebook 甚至是 TensorFlow 来训练一个可以识别一张图片是猫还是狗的模型。这是典型的监督学习二分类问题。虽然现在热门的技术可能会更轻松地解决这个曾经困难的问题，但通过在旧数据集上实施新技术，学习机器学习不久的工程师们将了解机器学习的未来挑战。  \n",
    "$~~~~~~~$本项目使用卷积神经网络 (Convolutional Neural Neteork, CNN) 模型。“卷积神经网路”一词表明该网络使用了**卷积**（convolution）这种数学运算。卷积是一种特殊的线性运算，卷积网络是指那些至少在网络的一层中使用卷积运算来替代一般的矩阵乘法运算的神经网络。在图像识别、语音识别等各种场合有着广泛应用。\n",
    "\n",
    "### 问题陈述\n",
    "$~~~~~~~$猫狗大战项目提供了25000张带有猫、狗的图片，分别存储了12500张在`test.zip`和`train.zip`压缩包下。使用`train.zip`下文件名带有`cat`或者`dog`标签的图片，对建立的卷积神经网络模型进行训练并改进，使其能够预测`test.zip`下任意一张图片是狗的可能性（可能性=1说明是狗，=0说明是猫）。  \n",
    "$~~~~~~~$考虑到这些图片存在着分辨率、尺寸不统一，猫、狗的姿态、品种、占图片比例以及背景的差异，特征选则和对象分类是必须的图像处理工作。首先，统一图片的分辨率、大小保证了模型将获得统一维度的输入向量。其次如前文所提及的，模型需要考虑的特征很多（我所提到的仅仅只是一部分），而这其中有不少是没有意义或者作用不大的特征，就需要使用正则化之类的方法，帮助我们找到那些重要的特征，例如图片中的边缘，形状，以及一些更高级的特征。然后，使用分类器，例如：Softmax，SVM 处理并输出分类结果。\n",
    "\n",
    "### 数据集和输入\n",
    "1. 数据集使用 Kaggle 的猫狗大战项目提供的12500张训练图片和12500张测试图片。其中训练集的12500张中猫和狗的图片各占50%，使用`cat`或者`dog`加上数字序号命名。测试集中同样包含猫和狗的图片，但是仅以数字序号命名。\n",
    "2. 数据集的预处理  \n",
    "    1. 对于输入图片，计算机识别的是一个像素矩阵（彩色图片则是一个三维数组），变换对象的大小、旋转角度或移动在图片中的位置对像素值都会有很大的影响。通过随机的平移、旋转或者翻转训练图片得到增强数据，并把它们加入到训练集，通过学习后算法更具有广泛性，测试结果也会更好，还有助于防止过拟合。\n",
    "    2. 在训练深度卷积神经网络前一般需要对数据进行预处理，预处理手段包括归一化处理，就是将数据映射，比如将图像像素[0，255]归一化到[0，1]。数据归一化有一下几点作用:\n",
    "\t\t1. 由于输入数据的数值不同，一部分数据像素值范围比较大，一部分像素值比较小，引发训练神经网络收敛慢、训练时间长。\n",
    "\t\t2. 训练图像数据像素范围如果比较大，则图像分类中的作用可能会偏大，而图像像素数据范围小的输入作用就可能会偏小。\n",
    "    3. 通过使用某种函数映射方法，将原数据中高维数据点通过某种函数映射到低维度的空间中，实现数据集降维。数据降维的目的是学习一个映射函数 ，其中 $x$ 是原始图像数据向量。 $y$ 是原始数据降维后的向量向量，一般 $y$ 的维度小于 $x$ 的维度。其中映射函数可以是线性的或非线性的、显式的或隐式的。  \n",
    "    通过使用降维算法，有效地去除噪声和糅杂信息所导致的误差，提高了识别的精度。\n",
    "\n",
    "### 解决方案阐明\n",
    "1. 模型的选择  \n",
    "通常我们可以很方便的搭建一个 CNN 模型，但是为了使得这个模型能够对测试集实现一个较好的预测效果，需要进行大量结构、参数等的调整。因此这里考虑使用迁移学习就显得至关重要了。可以对已有的表现较好的图像识别模型进行微调，从而实现较好的分类效果。  \n",
    "ImageNet 拥有超过1000000张图像的数据集，包含了各种各样的图片，其中就包括本项目中设计的猫、狗两类，每年都会举办是用这个巨大数据集的 ILSVRC 图像识别大赛，其测试项目之一就有“类别分类”。自2012年的基于深度学习的ALexNet大幅降低了错误识别率，此后基于深度学习的方法不断在提升识别精度，这些年深度学习取得了不斐的成绩，其中 VGG、 GoogleNet、 ResNet 表现尤为突出且已被技术人员广泛应用。  \n",
    "使用在IMAGENET训练集上已经训练好的模型，然后我们把卷积层以后的部分去掉，加上全新的未训练的层（相当于把卷积的部分保留并冻结，重新训练分类的部分），然后用我们提供的新的训练集进行二次训练。相比直接在我们的训练集上训练一个全新的模型，迁移学习节省了大量的计算成本，同时因为IMAGENET数据集足够强大，可以导致更好的效果。最后，本项目选则目前较新的 InceptionV3、ResNet50、 Xception 这三个模型。\n",
    "2. 数据预处理方案  \n",
    "   1. 通过对图片中的色彩-像素比进行 IQR 分析，初步筛选出了250张分辨率低、无关的图片，再对这些图片人工核查，选则不合格的图片删除\n",
    "   <img src=\"outlier_examples.jpg\" width=\"80%\"/>\n",
    "   2. 对于 InceptionV3，输入要求必须3层通道，并且宽高不得低于139，如果`include_top`为`False`，则要求必须是`(299, 299, 3)`或者`(3, 299, 299)`。输出层是`GlobalAveragePooling2D`；预处理将数据从`(0, 255)`缩放到`(-1, 1)`进行归一化。\n",
    "   3. 对于 ResNet50 ，输入要求必须3层通道，并且宽高不得低于197，如果`include_top`为`False`，则要求必须是`(224, 224, 3)`或者`(3, 224, 224)`。输出层是`Flatten`；预处理首先，这些图像的通道顺序为 RGB，我们需要重排他们的通道顺序为 BGR；其次，预训练模型的输入都进行了额外的归一化过程。因此我们在这里也要对这些张量进行归一化，即对所有图像所有像素都减去像素均值 `[103.939, 116.779, 123.68]`（以 RGB 模式表示，根据所有的 ImageNet 图像算出）。\n",
    "   4. 对于 Xception，输入要求必须3层通道，并且宽高不得低于71，如果`include_top`为`False`，则要求必须是`(299, 299, 3)`或者`(3, 299, 299)`。输出层是`GlobalAveragePooling2D`；预处理将数据从`(0, 255)`缩放到`(-1, 1)`进行归一化。\n",
    "   \n",
    "\n",
    "### 基准模型\n",
    "$~~~~~~~$使用调整后的 InceptionV3、ResNet50、 Xception 模型的前几层来提取浅层特征，然后最后使用 softmax 分类我们自己的数据集。我们可以不必对模型进行完全重新训练，从而提高效率，因为训练一个全新模型的准确度通常从非常低的值开始缓慢增加，但是 Finetune 算法可以使我们迭代更新参数更少的次数获得更好的精度结果。\n",
    "考虑到我们的数据集与原始 ImageNet 训练数据相似：\n",
    "- 删除神经网络的最后层级\n",
    "- 添加一个新的完全连接层，与新数据集中的类别数量相匹配\n",
    "- 随机化设置新的完全连接层的权重；冻结预先训练过的网络中的所有权重\n",
    "- 训练该网络以更新新连接层的权重\n",
    "\n",
    "$~~~~~~~$选择的三个预训练模型在 Finetune 之前的训练参数均为 8194 个，本项目将针对模型各自的特点设置相应的 Finetune 范围，增加训练参数的个数，提升训练效果。\n",
    "\n",
    "### 评估指标\n",
    "$~~~~~~~$在 2013 年发起的第一次猫狗大战项目中，使用__准确率__作为性能评估的指标，是用这个简单的指标也许是基于当时的图像识别的算法发展的水平、硬件性能等综合考虑的结果。在 2016 年重新发起的 Kernels Edition 中，使用误差函数：$$\\textrm{LogLoss} = - \\frac{1}{n} \\sum_{i=1}^n \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i)\\right],$$其中\n",
    "- n 表示测试集图片的数量\n",
    "- $\\hat{y}_{i}$ 表示图片是狗的预测概率\n",
    "- $y_{i}$ 图片是狗为1，是猫为0\n",
    "- $log()$ 以 e 为底的对数函数\n",
    "\n",
    "$~~~~~~~$在如今的深度学习神经网络的优化过程中，使用误差函数配合梯度下降法是非常常见且普遍的做法。通过优化模型，使得模型能狗呈现出更好的分类效果，也便于对模型做出更合理的评价。本项目要达到 Kaggle Public Leaderboard 前 10%，目前一共有1314位参赛者，而第131位的分数为0.06127，确定目标分数为 0.06。\n",
    "\n",
    "### 项目设计\n",
    "$~~~~~~~$基于前文的分析，本项目将主要分为遵循数据预处理，模型建立，模型训练，模型调整，评估模型的大体思路去执行。\n",
    " - 将下载自 kaggle 的图片，按`dog` 和 `cat` 分别存放\n",
    " - 数据预处理主要进行统一输入维度，统一输出层，将原有的训练数据分配训练集和验证集；\n",
    " - 模型建立主要确定了基于 InceptionV3、ResNet50、 Xception 这三个模型进行迁移学习；\n",
    " - 使用预处理后的数据后，首次 dropout 取 0.5，连接输出层，激活函数使用 sigmoid，优化器使用 Adam，最终输出一个 0 维张量；\n",
    " - 用 LogLoss 对模型进行评估，；\n",
    " - 模型调整将根据评估结论对模型的某些层再做优化；\n",
    " - 可视化模型的训练曲线，模型分类结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "## 参考文献\n",
    "[1] Karen Simonyan and Andrew Zisserman（2014）: Very Deep Convolutional Networks for Large-Scale Image Recognition. arXiv:1409.1556 [cs] (September 2014).  \n",
    "[2] Alec Radford, Luke Metz, and Soumith Chintala（2015）: Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. arXiv:1511.06434 [cs] (November 2015).  \n",
    "[3] A. Mahendran and A. Vedaldi（2015）: Understanding deep image representations by inverting them. In 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 5188 – 5196.  \n",
    "[4] Donglai Wei, Bolei Zhou, Antonio Torralba, William T. Freeman（2015）: mNeuron: A Matlab Plugin to Visualize Neurons from Deep Models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
